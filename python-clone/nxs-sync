#!/usr/bin/env python3

import yaml
import subprocess
import argparse
import pycurl
import xml.etree.ElementTree as ET
import os
import base64
import smtplib
import glob
import tempfile

#get username and password from config
def get_user_from_cfg(servername):
    for i in config['server'][servername]['connect']:
        if i[:4] == 'pass':
            password=i.split()[2]
            continue
        if i[:4] == 'user':
            user=i.split()[2]
            continue
    return(user,password)

def send_mail(recipient, body):
    from email.mime.text import MIMEText
    sender = 'live.it@bk.ru'

    msg = MIMEText(body, "", "utf-8")
    msg['Subject'] = 'Nixys.Storage [sync]: quota near to be exceeded for user '
    msg['From'] = sender
    msg['To'] = recipient

    #print (body, recipient)
    s = smtplib.SMTP('localhost:25')
    s.sendmail(sender, recipient, msg.as_string())
    s.quit()
    print ('mail send')

#Check webdav storage usage and write to stat file. If quota exceeded call send alert mail function (send_mail())
def get_quota_usage(servername):
    user = get_user_from_cfg(servername)
    command = "curl --silent -u " + user[0] +':'+ user[1]+"  -X PROPFIND  \'https://storage.nixys.ru/remote.php/webdav/\' | xmllint --format -"
    out = exec_cmd(servername, command)
    storage_stat = ET.fromstring(out['stdout'])

    quota_used = int(storage_stat[0][1][0][2].text)
    quota_total = int(storage_stat[0][1][0][3].text)+quota_used
    print('usage stat:', quota_used, quota_total)
    f = open(config['server'][servername]['quota_stat'], 'w')
    f.write(str(quota_used)+' '+str(quota_total))
    f.close()

    print('stat file created')
    usage_percent = round(quota_used/quota_total*100, 2)
    print ('storage used: ', usage_percent,'%')
    quota_alert = int(config['server'][servername]['quota_alert'])
    if usage_percent > quota_alert:
        body = 'Quota used percents more then ' + str(quota_alert) + '% (current used space: ' + str(quota_used) + '/' + str(quota_total) + ' bytes (' + str(usage_percent)+ '%))'
        send_mail(config['server'][servername]['admin_email'], body)
    return (usage_percent)

#get password hash
def generate_pass (servername):
    cmd = 'rclone obscure '+ str(servername)
    p = subprocess.Popen(cmd, shell=True,  stdout=subprocess.PIPE)
    out = p.stdout.read().decode('utf-8')
    return (out)

#create rclone config file
def create_conf(servername):
    f = open('rclone.conf', 'w')
    f.write('['+servername+']'+'\n' )
    for i in config['server'][servername]['connect']:
        if i[:4] == 'pass':
            q=i.split()[2]
            f.write('pass = '+ generate_pass(q) +'\n')
            continue
        f.write(i +'\n')
    f.close()
    #print ('config file created')
    
def sync_start(servername, sorted_list):
    #includes = " --include ".join(inc_files(config['server'][servername]['fs_root'], config['server'][servername]['include']))
    #print (includes)
    #excludes = " --exclude ".join(config['server'][servername]['excludes'])
    #print(excludes)
    filtered = "\" --filter=\"".join(sorted_list)
    options = " ".join(config['server'][servername]['options'])
    cmd = 'rclone --config rclone.conf --log-file='+config['server'][servername]['logfile_path']+servername+'-sync.log  --log-level '+config['server'][servername]['loglevel']+' sync '+ config['server'][servername]['fs_root']+ ' '+ servername +':'+ config['server'][servername]['storage_root'] + ' --filter="'+filtered +'" --bwlimit='+config['server'][servername]['upload_speed_limit'] + ' '+options 
    return (cmd)

#' --exclude '+ excludes +
#+' --include '+ includes
#' --exclude-from '+ config['server'][servername]['exclude_from_file']+

def create_filtering_list(servername):
    inclide = config['server'][servername]['include']
    exclude = config['server'][servername]['excludes']
    fs_root = config['server'][servername]['fs_root']
    sorted_list = []

    for i in inclide:
        if  i.find(':') == True:
            files_number = i.split(":")[0]
            files_path = fs_root + i.split(":")[1]
            for j in range (int(files_number)):
                z = int('-'+str(j))
                filtered_files = sorted(glob.iglob(files_path), key=os.path.getctime)[z]
                cut_path = '+ '+ filtered_files.replace(fs_root, '', 1)
                sorted_list.append(cut_path)
        else:
            files_path = fs_root + i
            all_files_path = sorted(glob.iglob(files_path))
            for j in all_files_path:
                cut_path = '+ ' + j.replace(fs_root, '', 1)
                sorted_list.append(cut_path) 
    for i in exclude:
        files_path = fs_root + i
        all_files_path = sorted(glob.iglob(files_path))
        for j in all_files_path:
            cut_path = '- ' + j.replace(fs_root, '', 1)
            sorted_list.append(cut_path)
    return (sorted_list)

'''''
def inc_files(fs_root,files_path):
    for i in files_path:
        a = i.split(":")[0]
        b = fs_root + i.split(":")[1]
        print (b)
        sorted_list = []
        for j in range (int(a)):
            z = int('-'+str(j))
            x = sorted(glob.iglob(b), key=os.path.getctime)[z]
            cutx = x.replace(fs_root, '', 1)
            sorted_list.append(cutx)
    print (sorted_list)
    return sorted_list
'''''

def trim_slash(remote_path):
    if remote_path[:1] == '/':
        remote_path = remote_path[1:]
    return (remote_path)

def exec_cmd(servername, cmdline):
    create_conf(servername)
    data_dict = {}
    
    current_process = subprocess.Popen([cmdline], stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
    data = current_process.communicate()

    data_stdout = data[0][0:-1].decode('utf-8')
    data_stderr = data[1][0:-1].decode('utf-8')

    data_dict['stdout'] = data_stdout
    data_dict['stderr'] = data_stderr

    #os.remove('rclone.conf')

    return data_dict

#parsing command line arguments
def parse_args():
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest='cmd', help='List of commands')

    start_parser = subparsers.add_parser('start', help='Start sync from local server to remote')
    start_parser.add_argument('servername', type=str, help='Remote server name')

    list_parser = subparsers.add_parser('ls', help='List all the objects path with modification time, size and path')
    list_parser.add_argument('servername', type=str, help='Remote server name')
    list_parser.add_argument('dirname', type=str, help='Directory to list, / for root')

    tree_parser = subparsers.add_parser('tree', help='List the contents of the remote in a tree')
    tree_parser.add_argument('servername', type=str, help='Remote server name')
    tree_parser.add_argument('dirname', type=str, help='Directory to list, / for root')

    copy_parser = subparsers.add_parser('copyto', help='Copy from local server to remote')
    copy_parser.add_argument('servername', type=str, help='Remote server name')
    copy_parser.add_argument('source', help='Set "From" destination')
    copy_parser.add_argument('destination', help='Set "To" destination. For remote use [remote server]:[path]')

    restore_parser = subparsers.add_parser('restore', help='Copy from remote to local server')
    restore_parser.add_argument('servername', type=str, help='Remote server name')
    restore_parser.add_argument('source', help='Remote path')
    restore_parser.add_argument('destination', help='Local destination')

    purge_parser = subparsers.add_parser('purge', help='Remove the path and all of its contents')
    purge_parser.add_argument('servername', type=str, help='Remote server name')
    purge_parser.add_argument('dirname', type=str, help='Directory to list, / for root')

    size_parser = subparsers.add_parser('size', help='Prints the total size and number of objects in [remote server]:[path]')
    size_parser.add_argument('servername', type=str, help='Remot server name')
    size_parser.add_argument('dirname', type=str, help='Directory size, / for root')

    return parser.parse_args()

#open configuration file
with open("conf.yaml") as stream:
    try:
        config = yaml.load(stream)
    except yaml.YAMLError as exc:
        print(exc)

#check command line arguments
args = parse_args()
if args.cmd == 'ls':
    args.dirname = trim_slash(args.dirname)
    command = 'rclone --config rclone.conf --dry-run  lsl ' + args.servername+ ':'+args.dirname
    out = exec_cmd(args.servername, command)
    print (out['stdout']) 
elif args.cmd == 'tree':
    args.dirname = trim_slash(args.dirname)
    command = 'rclone --config rclone.conf --dry-run tree ' + args.servername+ ':'+args.dirname
    out = exec_cmd(args.servername, command)
    print (out['stdout']) 
elif args.cmd == 'size':
    args.dirname = trim_slash(args.dirname)
    command = 'rclone --config rclone.conf --dry-run  size ' + args.servername+ ':'+args.dirname
    out = exec_cmd(args.servername, command)
    print (out['stdout']) 
elif args.cmd == 'copyto':
    args.destination = trim_slash(args.destination)
    command = 'rclone --config rclone.conf --log-file='+config['server'][args.servername]['logfile_path']+args.servername+'-sync.log --log-level '+config['server'][args.servername]['loglevel'] + ' '+ ' copy ' + args.source +' '+ args.servername+ ':'+ args.destination
    out = exec_cmd(args.servername, command)
    print (out['stdout']) 
elif args.cmd == 'restore':
    args.source = trim_slash(args.source)
    command = 'rclone --config rclone.conf --log-file='+config['server'][args.servername]['logfile_path']+args.servername+'-sync.log --log-level '+config['server'][args.servername]['loglevel'] + ' '+ ' --dry-run copy ' + args.servername+ ':'+args.source +' '+ args.destination
    out = exec_cmd(args.servername, command)
    print (out['stdout']) 
elif args.cmd == 'purge':
    args.dirname = trim_slash(args.dirname)
    command = 'rclone --config rclone.conf --log-file='+config['server'][args.servername]['logfile_path']+args.servername+'-sync.log --log-level '+config['server'][args.servername]['loglevel']+ ' purge '  + args.servername+ ':'+args.dirname
    out = exec_cmd(args.servername, command)
    print (out['stdout']) 
elif args.cmd == 'start':
    sorted_list = create_filtering_list(args.servername)
    print (sorted_list)
    command = sync_start(args.servername, sorted_list)
    print (command)
    exec_cmd(args.servername, command)
    if args.servername == 'nxs-storage':
        get_quota_usage(args.servername)
    print('sync started')
else:
    print ('use --help')
